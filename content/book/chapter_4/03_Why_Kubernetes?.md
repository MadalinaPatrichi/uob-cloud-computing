Previously, we discussed how the evolution of deploying software modules into standardised packages that could run nearly anywhere was called containers, or containerisation. As I mentioned previously, this movement towards containerisation has created a new need, to define and manage the lifecycle of these containers and how these containers interact with each other to create a larger, interesting and useful software system.

The de facto standard for container orchestration is now Kubernetes. So, how did Kubernetes come about? Well, Google learned a lot of lessons in their decade of experience with containers . They were running applications and containers far before anyone else and they were able to manage it. What they then did was to turn all of those lessons into what Kubernetes is today. . They were able to solve their own problems and then provide it to the community a a hey, here, we’ve done this for a while and we know the pains and we had the resources to create this .Kubernetes was born at a project of Google’s internal need for container orchestration. It was first announced in 2014, as project Borg, and it has grown into a mature product, currently at version 1.8, with support and growth in the enterprise and most major cloud providers. Kubernetes, as a product, is governed in standards and deployment and development by a public process led by the Cloud Native Computing Foundation , also known as the CNCF. Much like the Linux model, Kubernetes has itself been repackaged into distributions with support and other commercialised offerings by large vendors, many of whom themselves are members of the CNCF, with many of the improvements and the changes that they make going back into the open-source project. Kubernetes enjoys a major lead in technology maturity and adoption for a variety of reasons. First, Kubernetes and its predecessor, Google Borg, go back to the very beginning of container orchestration. It simply has a head start on solving a very complicated problem, but that’s not enough for it to automatically become the standard in container orchestration. What also contributed to the success of the project are the people around it. What made the project so popular is the fact that its founders have taken all the proprietary knowledge, preserved and grew it through the CNCF and involved the public community for its maintenance and expansion. This allowed Kubernetes to grow unlike proprietary technologies. Kubernetes has gained the trust and commitment of its users and the open-source community in large part by avoiding vendor lock-in, but allowing access to the kind of support and assured quality large vendors can offer through their own distributions. That is not to say that Kubernetes was, or is without its competitors; Docker, the company that created Docker containers themselves, that Kubernetes uses by default has its own orchestration offering for example. However, as it relates to Docker Swarm or even Apache Mesos, another mature orchestration project, Kubernetes has several distinct advantages at the moment.

First, its lineage has given it quite a lead time in both time and pedigree; it of course, never hurts to be born at Google, solving problems at Google scale.

Second, it’s not just achieved critical mass, it’s actually grown to sustainability; and the CNCF organisation provides some permanence to this, especially as every major cloud vendor, including OCI and many major software vendors have joined the organisation. As for the code, just look at the commits,  follows and stars of the various Kubernetes projects, they speak for themselves.

Third, Kubernetes offers auto-scaling that continues to mature and does not introduce provider specific details, but lets you leverage many cloud providers implementation by abstracting them intelligently into common configuration files. This makes for an ease of deployment across hybrid clouds,  or public clouds, or any type of deployment infrastructure.

Kubernetes is a technology and software package you can run on your own, of your laptop, your own server hardware, you data centers, cloud providers,  or a combination of them all if you’s like.
